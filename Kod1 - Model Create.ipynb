{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a8c320-b337-4db0-bef5-481e5bfc838a",
   "metadata": {},
   "source": [
    "**Część pierwsza: instalacja oraz aktualizacja potrzebnych bibliotek.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee46a22-71c7-4ab9-8fb2-41563cdfc14e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from kaggle) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: bleach in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from requests->kaggle) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from requests->kaggle) (3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Requirement already satisfied: gensim in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
      "Requirement already satisfied: keras in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from keras) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\aleks\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "#installing imorant kaggle and other important code fragments \n",
    "!pip install kaggle\n",
    "!pip install gensim --upgrade\n",
    "!pip install keras --upgrade\n",
    "!pip install pandas --upgrade\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687220fc-4a69-4aab-ba3b-dcef8c583e8c",
   "metadata": {},
   "source": [
    "**Część druga: import bibliotek i rozszerzeń**\n",
    "\n",
    "\n",
    "Scikit-learn - uczenie maszynowe oraz analiza danych \n",
    "\n",
    "Keras - procesowanie i analiza danych, zamiana tekstu na tokeny\n",
    "\n",
    "Matplot - rysowanie wykresów (wykorzystane później w celu narysowania zysków/strat efektywności w algorytmie na przestrzeni pokoleń)\n",
    "\n",
    "Nltk - nardzędzia przydatne w tworzeniu modeli językowych\n",
    "\n",
    "Gensim - biblioteka open-source dla modeli tematów\n",
    "(model tematów - model uczenia nienadzorowanego, w którym wyciąga się najważniejsze informacje z tekstu poprzez groupwanie słów i znaczeń)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2872100-cdd5-4b5a-8639-b6863f6fae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Matplot\n",
    "#rysowanie wykresów (wykorzystane później w celu narysowania zysków/strat efektywności w algorytmie na przestrzeni pokoleń)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn\n",
    "# preprocesing danych, ocena modeli, abstrahowanie (feature extraction) - wyciąganie najważniejszych informacji \n",
    "from sklearn.model_selection import train_test_split #Podział danych na testowe i uczące\n",
    "from sklearn.preprocessing import LabelEncoder #Będzie umożliwiał otagowanie tekstów ich ich klasą \n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score #Do póżniejszego oceniania modelu i pokazanie jego wyników na tabeli \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Keras\n",
    "#Przede wszystkim tworzenie i uczenie modeli, także procesowanie i analiza danych, zamiana tekstu na tokeny. \n",
    "#Jest to API uczenia maszynowego między człowiekiem a pythonem. \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer #\"Tokenizer\" umożlwiia zamianę słów i wyrazów na tokeny, czyli znacznie / viby, lub idee w sensie platonicznym.\n",
    "#Przykładem tokenu jest pies, które może być wyrażone za pomocą słowa \"dog\", \"hound\", \"doggy\", \"puppy\" itp. \n",
    "#Tokenem może być słowo, podsłowo (podzbiór słowa), a nawet pojedynczy znak.\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM #narzędzia tworzenia modelu, w szczególności warst neuronów\n",
    "#Activation - algorytm determinujący, dla jakich danych neuron się aktywuje\n",
    "#Dense - warstwa połączeń wszyscy do wszystkich\n",
    "#Dropout - przeciwdziała przetrenowaniu\n",
    "#Embedding - zamiana liczb (intigers) na wektory. W szczególności użytecne w modelach językowych (opartych na wektorach opisujących zależności między słowami)\n",
    "#Flatten - redukcja wymiarowości bez zmiejszania próby (np. z 3 x 3 na 1 x 9), szczególnie przydatne dla warstwy \"dense\" (wszystko do wszystkich)\n",
    "#Max pooling - sygnały stike back - zmiejszanie matrycy przez \"przejechanie\" po niej filterm. [1,5,10,6; 3,11,9,6 ; 4,3,1,1, ; 16,9,2,2] -> [11,10 ; 16,2]\n",
    "#Long Short-Term Memory (długotrwała pamięć skrótkotrwała) - jeden z trików na problem zanikającego gradientu\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# nltk \n",
    "import nltk\n",
    "#NLTK oznacza Natural Language Toolkit\n",
    "from nltk.corpus import stopwords \n",
    "#stopwords - słowa generalnie bez informacji, jak np. \"the\", \"an\", \"a\" w języku angielskim \n",
    "from  nltk.stem import SnowballStemmer\n",
    "#Stemming to redukcja słowa do jego słowa bazowego lub rdzenia w taki sposób, że słowa podobnego rodzaju znajdują się pod wspólnym rdzeniem. \n",
    "#Na przykład – słowa care, cared i caring znajdują się pod tym samym rdzeniem „care”\n",
    "\n",
    "# Word2vec\n",
    "#Self-explanatory\n",
    "import gensim\n",
    "# biblioteka open-source dla modeli tematów\n",
    "#model tematów - model uczenia nienadzorowanego, w którym wyciąga się najważniejsze informacje z tekstu poprzez groupwanie słów i znaczeń\n",
    "\n",
    "# Utility\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# Set log\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07067034-822b-4dc2-827e-48d46d68c9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aleks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pobranie \"Stop wordów\" \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65c73a59-737b-4b01-bd89-4165220ad617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "# Informacje jak wyglądają dane odnośnie twitów\n",
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"] #W bazie danych mamy 7 kolumn, gdzie najważniejsze (tekst i sentyment) to pierwsza i ostatnia\n",
    "#target - czy twitt jest pozytywny (4), neutralny (2) lub negatywny (0). \"Flag\" to najprawdopodobniej metadata. \n",
    "#Każdy twitt też ma id \"ids\", datę zapostowania  \"date\", autora \"user\" oraz sam tekst - \"text\"\n",
    "DATASET_ENCODING = \"ISO-8859-1\" #często używane w zbiorze dancych w których występują znaki specjalne \n",
    "TRAIN_SIZE = 0.8 #jaki % danych będzie użyte do czenia, a jaki procent do testowania\n",
    "\n",
    "# TEXT CLEANING\n",
    "# usunięcie przedrostków https albo http z tekstu\n",
    "TEXT_CLEANING_RE = r\"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "# WORD2VEC\n",
    "# osadzenie słów\n",
    "W2V_SIZE = 300 #Ile wymiarów będzie posiadał słowo-wektor\n",
    "W2V_WINDOW = 7 #Na ile wyrazów obok będzie patrzył model tworząc powiązania\n",
    "W2V_EPOCH = 32 #Liczba pokoleń\n",
    "W2V_MIN_COUNT = 10 #Limit - jeżeli wyraz pojawia się mniej niż minimalną liczbę razy (tutaj 10), będzie ignorowany  \n",
    "\n",
    "# KERAS\n",
    "# wprowadzenie parametrów uczenia maszynowego\n",
    "SEQUENCE_LENGTH = 300 #maksymalna długość tekstu wprowadzone \n",
    "EPOCHS = 8 #Liczba pokoleń\n",
    "BATCH_SIZE = 1024 #Liczba tekstów analizowanych w jednym pokoleniu - im więcej tym lepszy proces uczenia, ale zajmuje więcej czasu\n",
    "\n",
    "# SENTIMENT\n",
    "#Przypisanie rezultatów do skali liczbowej, przypisanie nazw do rezultatów \n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "#Innymi słowy below 0.4 : Negative, 0.4.-0.7 : Neutral, above 0.7 (Positive) \n",
    "\n",
    "# EXPORT\n",
    "#Jak będzie nazwany model po eksporcie \n",
    "KERAS_MODEL = \"model.h5\"\n",
    "WORD2VEC_MODEL = \"model.w2v\"\n",
    "TOKENIZER_MODEL = \"tokenizer.pkl\"\n",
    "ENCODER_MODEL = \"encoder.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8f489-0d72-478e-a862-a23b9707ec30",
   "metadata": {},
   "source": [
    "**Dataset details**\n",
    "\n",
    "target: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "\n",
    "ids: The id of the tweet (2087)\n",
    "\n",
    "date: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "\n",
    "flag: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "\n",
    "user: the user that tweeted (robotickilldozr)\n",
    "\n",
    "text: the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f76a376-c757-4ee5-ac0e-53b4a8490b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open file: C:\\Users\\aleks\\Downloads\\training.1600000.processed.noemoticon.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_path = r\"C:\\Users\\aleks\\Downloads\\training.1600000.processed.noemoticon.csv\"\n",
    "print(\"Open file:\", dataset_path)\n",
    "df = pd.read_csv(dataset_path, encoding =DATASET_ENCODING , names=DATASET_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3290854-7d28-480f-980f-35d323d65e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1600000\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35bbbe41-1480-4086-8e64-a7c651c2b888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f07735-e98f-4b86-86b3-62f60d97480d",
   "metadata": {},
   "source": [
    "**Klasa z numeru jest zamieniana na tekst (intiger into string)**\n",
    "\n",
    "0 -> NEGATIVE\n",
    "\n",
    "2 -> NEUTRAL\n",
    "\n",
    "4 -> POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32a99929-0c31-4d2f-94fa-fa858928df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Klasa z numeru jest zamieniana na tekst (intiger into string)\n",
    "\n",
    "decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"} #przypisanie tekstu do tagu klasy\n",
    "def decode_sentiment(label): #definicja funkcji, która odczytuje metki / taki / labelki (label) i przyłączy im ich tekstowy odpowiednich zgodnie z słownikiem \"decode_map\"\n",
    "    return decode_map[int(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90759ea1-2eb2-49c3-90c6-a91d31d2a381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 219 ms\n",
      "Wall time: 226 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.target = df.target.apply(lambda x: decode_sentiment(x)) # Konwertuje numeryczne etykiety sentymentu w kolumnie 'target' DataFrame na ich tekstowe odpowiedniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06593011-ec28-4861-b942-92a927b90c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Dataset labels distribuition')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tabela preentująca podział klas w danych twittów\n",
    "target_cnt = Counter(df.target)\n",
    "\n",
    "#konfiguracja wykresu \n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(target_cnt.keys(), target_cnt.values())\n",
    "plt.title(\"Dataset labels distribuition\") #tytuł wykresu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107c3486-565b-4419-9277-48bcc4ba2b2c",
   "metadata": {},
   "source": [
    "**Tabela preentująca podział klas w danych twittów**\n",
    "\n",
    "Jak widać twittów negatywnych jest około tyle samo ile twittów pozytywnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0a3dde7-8fe8-41fb-826e-b06e74ac116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Process dataset - pobranie danych służących czyszczeniu danych \n",
    "\n",
    "stop_words = stopwords.words(\"english\") #stop words to słowa bez własnego znaczenia, w angielskim będą to \"the\", \"an\", \"a\" itd.\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\") #Stemmer, od \"stem\" czyli łodyga/pień, to centralne znaczenie słowa. \n",
    "#Stemmering to proces sprowadzenia słowa do jego podstawowego znaczenia, np. \"runnning\" zamieniamy na \"run\". Jest to zmiejszanie wariacji / wymiarowości słów w tekście"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8062f00e-8740-4f86-acd6-d3b84425849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocesing - rozbicie tekstu na tokeny (słowa/wyrazy), usunięcie stopwordów (zbędnych wyrazów) \n",
    "\n",
    "def preprocess(text, stem=False): \n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip() #usuwanie wielkich liter [.lower()] i odstępów (ang. whitespace) na początku i końcu tekstu [.strip()]\n",
    "    #usuwa fragmenty \"https\" oraz \"http\" przez usunięcie wszystkiego co pasuje do fragmentu z początku - TEXT_CLEANING_RE\n",
    "    \n",
    "    tokens = [] #tworzymy pustą lista na dodanie tokenów \n",
    "    \n",
    "    for token in text.split(): #rozbicie tekstu na tokeny (słowa), przez rozbicia w miejscach spacji\n",
    "        if token not in stop_words: #stop wordy nie będą miały własnego znaczenia, będą miały znikomą korzyść dla analizy i są ignorowane \n",
    "\n",
    "            #możliwe stemowanie - zamiana tokenu na jego formę podstawoą \n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token)) #stem = True - token jest dodany do listy jego wcześniejszym uproszczeniu \n",
    "            else:\n",
    "                tokens.append(token) #stem = False - po prostu dodajemu token do listy \n",
    "                \n",
    "    return \" \".join(tokens) #zwracamy tekst (w formie tokenów, pozbawiony wyrazów zbędnych) oddzielonych spacjami "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a262649b-984c-47ac-aba5-7cda2dec59d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 29.7 s\n",
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.text = df.text.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68ae07b2-04ef-4aa8-8380-84607810fcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN size: 1280000\n",
      "TEST size: 320000\n"
     ]
    }
   ],
   "source": [
    "#Podział na dane testowe (test) oraz uczące (train)\n",
    "#TRAIN_SIZE = 0.8, danych uczących będzie 80%, danych testowych 20%\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=1-TRAIN_SIZE, random_state=42)\n",
    "#random state ułatwia analizę kodu przez eliminację losowości, jednocześnie umożliwiając jej póżniejsze dodanie i eksperymenty przez zmienianie random state\n",
    "print(\"TRAIN size:\", len(df_train)) #wyświetlanie wielkości zbioru uczącego\n",
    "print(\"TEST size:\", len(df_test)) #wyświetlanie wielkości zbioru testowego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78099b2c-eb80-4318-aebc-5ef072beb51e",
   "metadata": {},
   "source": [
    "Słowa -> Wektory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d46646ab-671a-481b-82f9-7a748542b721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2 s\n",
      "Wall time: 2.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "documents = [_text.split() for _text in df_train.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45a8531c-b53a-4c4e-b6e5-c5f380f9b853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 12:36:00,836 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.025>', 'datetime': '2024-12-17T12:36:00.836629', 'gensim': '4.3.3', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "#Zamiane słów na wektory, w oparciu o warunki ustalone na początku kodu\n",
    "#Dla przypomnienia \n",
    "#W2V_SIZE = 300 - tyle wymiarów ma wektor\n",
    "#W2V_WINDOW = 7 - tyle wyrazów z sąsiedztwa będziemy analizować\n",
    "#W2V_MIN_COUNT = 10 - ile minimalnie musi wyraz wystąpić, żeby był analizowany \n",
    "\n",
    "w2v_model = gensim.models.word2vec.Word2Vec(vector_size=W2V_SIZE, \n",
    "                                            window=W2V_WINDOW, \n",
    "                                            min_count=W2V_MIN_COUNT, \n",
    "                                            workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5689edd7-f1e5-40c1-bf8f-0ef238dda380",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 12:36:00,841 : INFO : collecting all words and their counts\n",
      "2024-12-17 12:36:00,843 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-12-17 12:36:00,850 : INFO : PROGRESS: at sentence #10000, processed 72565 words, keeping 14005 word types\n",
      "2024-12-17 12:36:00,857 : INFO : PROGRESS: at sentence #20000, processed 144393 words, keeping 21587 word types\n",
      "2024-12-17 12:36:00,864 : INFO : PROGRESS: at sentence #30000, processed 215826 words, keeping 27541 word types\n",
      "2024-12-17 12:36:00,873 : INFO : PROGRESS: at sentence #40000, processed 288271 words, keeping 32764 word types\n",
      "2024-12-17 12:36:00,880 : INFO : PROGRESS: at sentence #50000, processed 359772 words, keeping 37587 word types\n",
      "2024-12-17 12:36:00,888 : INFO : PROGRESS: at sentence #60000, processed 431431 words, keeping 42198 word types\n",
      "2024-12-17 12:36:00,897 : INFO : PROGRESS: at sentence #70000, processed 503103 words, keeping 46458 word types\n",
      "2024-12-17 12:36:00,904 : INFO : PROGRESS: at sentence #80000, processed 575709 words, keeping 50476 word types\n",
      "2024-12-17 12:36:00,916 : INFO : PROGRESS: at sentence #90000, processed 647100 words, keeping 54140 word types\n",
      "2024-12-17 12:36:00,930 : INFO : PROGRESS: at sentence #100000, processed 718681 words, keeping 57777 word types\n",
      "2024-12-17 12:36:00,942 : INFO : PROGRESS: at sentence #110000, processed 790696 words, keeping 61207 word types\n",
      "2024-12-17 12:36:00,954 : INFO : PROGRESS: at sentence #120000, processed 863134 words, keeping 64583 word types\n",
      "2024-12-17 12:36:00,967 : INFO : PROGRESS: at sentence #130000, processed 935111 words, keeping 67865 word types\n",
      "2024-12-17 12:36:00,979 : INFO : PROGRESS: at sentence #140000, processed 1006668 words, keeping 70966 word types\n",
      "2024-12-17 12:36:00,992 : INFO : PROGRESS: at sentence #150000, processed 1078512 words, keeping 74119 word types\n",
      "2024-12-17 12:36:01,005 : INFO : PROGRESS: at sentence #160000, processed 1149914 words, keeping 77187 word types\n",
      "2024-12-17 12:36:01,018 : INFO : PROGRESS: at sentence #170000, processed 1222145 words, keeping 80267 word types\n",
      "2024-12-17 12:36:01,032 : INFO : PROGRESS: at sentence #180000, processed 1294708 words, keeping 83393 word types\n",
      "2024-12-17 12:36:01,045 : INFO : PROGRESS: at sentence #190000, processed 1367608 words, keeping 86329 word types\n",
      "2024-12-17 12:36:01,060 : INFO : PROGRESS: at sentence #200000, processed 1439469 words, keeping 89103 word types\n",
      "2024-12-17 12:36:01,073 : INFO : PROGRESS: at sentence #210000, processed 1512099 words, keeping 91840 word types\n",
      "2024-12-17 12:36:01,086 : INFO : PROGRESS: at sentence #220000, processed 1584149 words, keeping 94636 word types\n",
      "2024-12-17 12:36:01,099 : INFO : PROGRESS: at sentence #230000, processed 1656354 words, keeping 97353 word types\n",
      "2024-12-17 12:36:01,113 : INFO : PROGRESS: at sentence #240000, processed 1728573 words, keeping 99975 word types\n",
      "2024-12-17 12:36:01,125 : INFO : PROGRESS: at sentence #250000, processed 1801102 words, keeping 102594 word types\n",
      "2024-12-17 12:36:01,138 : INFO : PROGRESS: at sentence #260000, processed 1873103 words, keeping 105162 word types\n",
      "2024-12-17 12:36:01,150 : INFO : PROGRESS: at sentence #270000, processed 1945245 words, keeping 107626 word types\n",
      "2024-12-17 12:36:01,163 : INFO : PROGRESS: at sentence #280000, processed 2017163 words, keeping 110141 word types\n",
      "2024-12-17 12:36:01,176 : INFO : PROGRESS: at sentence #290000, processed 2089574 words, keeping 112539 word types\n",
      "2024-12-17 12:36:01,188 : INFO : PROGRESS: at sentence #300000, processed 2160996 words, keeping 114893 word types\n",
      "2024-12-17 12:36:01,201 : INFO : PROGRESS: at sentence #310000, processed 2232913 words, keeping 117298 word types\n",
      "2024-12-17 12:36:01,214 : INFO : PROGRESS: at sentence #320000, processed 2305039 words, keeping 119693 word types\n",
      "2024-12-17 12:36:01,228 : INFO : PROGRESS: at sentence #330000, processed 2377119 words, keeping 122131 word types\n",
      "2024-12-17 12:36:01,241 : INFO : PROGRESS: at sentence #340000, processed 2449370 words, keeping 124416 word types\n",
      "2024-12-17 12:36:01,254 : INFO : PROGRESS: at sentence #350000, processed 2521564 words, keeping 126669 word types\n",
      "2024-12-17 12:36:01,267 : INFO : PROGRESS: at sentence #360000, processed 2593681 words, keeping 128912 word types\n",
      "2024-12-17 12:36:01,280 : INFO : PROGRESS: at sentence #370000, processed 2665692 words, keeping 131135 word types\n",
      "2024-12-17 12:36:01,293 : INFO : PROGRESS: at sentence #380000, processed 2737859 words, keeping 133403 word types\n",
      "2024-12-17 12:36:01,306 : INFO : PROGRESS: at sentence #390000, processed 2809848 words, keeping 135551 word types\n",
      "2024-12-17 12:36:01,319 : INFO : PROGRESS: at sentence #400000, processed 2882438 words, keeping 137742 word types\n",
      "2024-12-17 12:36:01,333 : INFO : PROGRESS: at sentence #410000, processed 2954075 words, keeping 139909 word types\n",
      "2024-12-17 12:36:01,346 : INFO : PROGRESS: at sentence #420000, processed 3026247 words, keeping 142144 word types\n",
      "2024-12-17 12:36:01,360 : INFO : PROGRESS: at sentence #430000, processed 3098659 words, keeping 144364 word types\n",
      "2024-12-17 12:36:01,372 : INFO : PROGRESS: at sentence #440000, processed 3170663 words, keeping 146439 word types\n",
      "2024-12-17 12:36:01,386 : INFO : PROGRESS: at sentence #450000, processed 3243344 words, keeping 148526 word types\n",
      "2024-12-17 12:36:01,398 : INFO : PROGRESS: at sentence #460000, processed 3315466 words, keeping 150610 word types\n",
      "2024-12-17 12:36:01,415 : INFO : PROGRESS: at sentence #470000, processed 3388295 words, keeping 152737 word types\n",
      "2024-12-17 12:36:01,428 : INFO : PROGRESS: at sentence #480000, processed 3460120 words, keeping 154757 word types\n",
      "2024-12-17 12:36:01,441 : INFO : PROGRESS: at sentence #490000, processed 3531883 words, keeping 156825 word types\n",
      "2024-12-17 12:36:01,452 : INFO : PROGRESS: at sentence #500000, processed 3604217 words, keeping 158859 word types\n",
      "2024-12-17 12:36:01,464 : INFO : PROGRESS: at sentence #510000, processed 3676427 words, keeping 160852 word types\n",
      "2024-12-17 12:36:01,473 : INFO : PROGRESS: at sentence #520000, processed 3749045 words, keeping 162863 word types\n",
      "2024-12-17 12:36:01,481 : INFO : PROGRESS: at sentence #530000, processed 3821622 words, keeping 164929 word types\n",
      "2024-12-17 12:36:01,489 : INFO : PROGRESS: at sentence #540000, processed 3893627 words, keeping 166840 word types\n",
      "2024-12-17 12:36:01,498 : INFO : PROGRESS: at sentence #550000, processed 3965477 words, keeping 168799 word types\n",
      "2024-12-17 12:36:01,507 : INFO : PROGRESS: at sentence #560000, processed 4038050 words, keeping 170802 word types\n",
      "2024-12-17 12:36:01,516 : INFO : PROGRESS: at sentence #570000, processed 4110296 words, keeping 172760 word types\n",
      "2024-12-17 12:36:01,524 : INFO : PROGRESS: at sentence #580000, processed 4182385 words, keeping 174635 word types\n",
      "2024-12-17 12:36:01,536 : INFO : PROGRESS: at sentence #590000, processed 4254632 words, keeping 176470 word types\n",
      "2024-12-17 12:36:01,550 : INFO : PROGRESS: at sentence #600000, processed 4326859 words, keeping 178350 word types\n",
      "2024-12-17 12:36:01,564 : INFO : PROGRESS: at sentence #610000, processed 4399183 words, keeping 180290 word types\n",
      "2024-12-17 12:36:01,579 : INFO : PROGRESS: at sentence #620000, processed 4471343 words, keeping 182129 word types\n",
      "2024-12-17 12:36:01,593 : INFO : PROGRESS: at sentence #630000, processed 4543286 words, keeping 184005 word types\n",
      "2024-12-17 12:36:01,607 : INFO : PROGRESS: at sentence #640000, processed 4615780 words, keeping 185835 word types\n",
      "2024-12-17 12:36:01,621 : INFO : PROGRESS: at sentence #650000, processed 4688481 words, keeping 187705 word types\n",
      "2024-12-17 12:36:01,636 : INFO : PROGRESS: at sentence #660000, processed 4760481 words, keeping 189439 word types\n",
      "2024-12-17 12:36:01,649 : INFO : PROGRESS: at sentence #670000, processed 4833024 words, keeping 191232 word types\n",
      "2024-12-17 12:36:01,663 : INFO : PROGRESS: at sentence #680000, processed 4904516 words, keeping 193177 word types\n",
      "2024-12-17 12:36:01,678 : INFO : PROGRESS: at sentence #690000, processed 4976968 words, keeping 194960 word types\n",
      "2024-12-17 12:36:01,690 : INFO : PROGRESS: at sentence #700000, processed 5049412 words, keeping 196725 word types\n",
      "2024-12-17 12:36:01,705 : INFO : PROGRESS: at sentence #710000, processed 5121976 words, keeping 198516 word types\n",
      "2024-12-17 12:36:01,718 : INFO : PROGRESS: at sentence #720000, processed 5193881 words, keeping 200325 word types\n",
      "2024-12-17 12:36:01,730 : INFO : PROGRESS: at sentence #730000, processed 5265467 words, keeping 202133 word types\n",
      "2024-12-17 12:36:01,744 : INFO : PROGRESS: at sentence #740000, processed 5337518 words, keeping 203818 word types\n",
      "2024-12-17 12:36:01,757 : INFO : PROGRESS: at sentence #750000, processed 5409321 words, keeping 205535 word types\n",
      "2024-12-17 12:36:01,770 : INFO : PROGRESS: at sentence #760000, processed 5481512 words, keeping 207282 word types\n",
      "2024-12-17 12:36:01,785 : INFO : PROGRESS: at sentence #770000, processed 5554093 words, keeping 209076 word types\n",
      "2024-12-17 12:36:01,799 : INFO : PROGRESS: at sentence #780000, processed 5625382 words, keeping 210805 word types\n",
      "2024-12-17 12:36:01,810 : INFO : PROGRESS: at sentence #790000, processed 5698066 words, keeping 212618 word types\n",
      "2024-12-17 12:36:01,825 : INFO : PROGRESS: at sentence #800000, processed 5770880 words, keeping 214374 word types\n",
      "2024-12-17 12:36:01,837 : INFO : PROGRESS: at sentence #810000, processed 5843418 words, keeping 216009 word types\n",
      "2024-12-17 12:36:01,850 : INFO : PROGRESS: at sentence #820000, processed 5915628 words, keeping 217804 word types\n",
      "2024-12-17 12:36:01,863 : INFO : PROGRESS: at sentence #830000, processed 5987499 words, keeping 219585 word types\n",
      "2024-12-17 12:36:01,877 : INFO : PROGRESS: at sentence #840000, processed 6058973 words, keeping 221344 word types\n",
      "2024-12-17 12:36:01,890 : INFO : PROGRESS: at sentence #850000, processed 6131125 words, keeping 223002 word types\n",
      "2024-12-17 12:36:01,903 : INFO : PROGRESS: at sentence #860000, processed 6202951 words, keeping 224643 word types\n",
      "2024-12-17 12:36:01,916 : INFO : PROGRESS: at sentence #870000, processed 6275461 words, keeping 226362 word types\n",
      "2024-12-17 12:36:01,935 : INFO : PROGRESS: at sentence #880000, processed 6347661 words, keeping 227986 word types\n",
      "2024-12-17 12:36:01,948 : INFO : PROGRESS: at sentence #890000, processed 6419806 words, keeping 229634 word types\n",
      "2024-12-17 12:36:01,960 : INFO : PROGRESS: at sentence #900000, processed 6491644 words, keeping 231389 word types\n",
      "2024-12-17 12:36:01,973 : INFO : PROGRESS: at sentence #910000, processed 6564022 words, keeping 233050 word types\n",
      "2024-12-17 12:36:01,985 : INFO : PROGRESS: at sentence #920000, processed 6636228 words, keeping 234686 word types\n",
      "2024-12-17 12:36:01,999 : INFO : PROGRESS: at sentence #930000, processed 6708573 words, keeping 236393 word types\n",
      "2024-12-17 12:36:02,014 : INFO : PROGRESS: at sentence #940000, processed 6779956 words, keeping 238052 word types\n",
      "2024-12-17 12:36:02,029 : INFO : PROGRESS: at sentence #950000, processed 6852599 words, keeping 239716 word types\n",
      "2024-12-17 12:36:02,043 : INFO : PROGRESS: at sentence #960000, processed 6924717 words, keeping 241354 word types\n",
      "2024-12-17 12:36:02,056 : INFO : PROGRESS: at sentence #970000, processed 6996992 words, keeping 242980 word types\n",
      "2024-12-17 12:36:02,070 : INFO : PROGRESS: at sentence #980000, processed 7068402 words, keeping 244646 word types\n",
      "2024-12-17 12:36:02,083 : INFO : PROGRESS: at sentence #990000, processed 7140346 words, keeping 246186 word types\n",
      "2024-12-17 12:36:02,096 : INFO : PROGRESS: at sentence #1000000, processed 7211757 words, keeping 247726 word types\n",
      "2024-12-17 12:36:02,110 : INFO : PROGRESS: at sentence #1010000, processed 7283267 words, keeping 249288 word types\n",
      "2024-12-17 12:36:02,124 : INFO : PROGRESS: at sentence #1020000, processed 7355299 words, keeping 250860 word types\n",
      "2024-12-17 12:36:02,138 : INFO : PROGRESS: at sentence #1030000, processed 7426918 words, keeping 252366 word types\n",
      "2024-12-17 12:36:02,151 : INFO : PROGRESS: at sentence #1040000, processed 7498815 words, keeping 253930 word types\n",
      "2024-12-17 12:36:02,165 : INFO : PROGRESS: at sentence #1050000, processed 7570499 words, keeping 255471 word types\n",
      "2024-12-17 12:36:02,179 : INFO : PROGRESS: at sentence #1060000, processed 7643251 words, keeping 257035 word types\n",
      "2024-12-17 12:36:02,192 : INFO : PROGRESS: at sentence #1070000, processed 7714721 words, keeping 258509 word types\n",
      "2024-12-17 12:36:02,205 : INFO : PROGRESS: at sentence #1080000, processed 7787371 words, keeping 260071 word types\n",
      "2024-12-17 12:36:02,218 : INFO : PROGRESS: at sentence #1090000, processed 7859336 words, keeping 261683 word types\n",
      "2024-12-17 12:36:02,231 : INFO : PROGRESS: at sentence #1100000, processed 7932029 words, keeping 263278 word types\n",
      "2024-12-17 12:36:02,244 : INFO : PROGRESS: at sentence #1110000, processed 8004146 words, keeping 264800 word types\n",
      "2024-12-17 12:36:02,258 : INFO : PROGRESS: at sentence #1120000, processed 8075880 words, keeping 266309 word types\n",
      "2024-12-17 12:36:02,271 : INFO : PROGRESS: at sentence #1130000, processed 8148163 words, keeping 267826 word types\n",
      "2024-12-17 12:36:02,285 : INFO : PROGRESS: at sentence #1140000, processed 8220487 words, keeping 269391 word types\n",
      "2024-12-17 12:36:02,299 : INFO : PROGRESS: at sentence #1150000, processed 8292498 words, keeping 270894 word types\n",
      "2024-12-17 12:36:02,313 : INFO : PROGRESS: at sentence #1160000, processed 8363838 words, keeping 272400 word types\n",
      "2024-12-17 12:36:02,327 : INFO : PROGRESS: at sentence #1170000, processed 8435510 words, keeping 273970 word types\n",
      "2024-12-17 12:36:02,342 : INFO : PROGRESS: at sentence #1180000, processed 8507795 words, keeping 275521 word types\n",
      "2024-12-17 12:36:02,357 : INFO : PROGRESS: at sentence #1190000, processed 8579080 words, keeping 277007 word types\n",
      "2024-12-17 12:36:02,370 : INFO : PROGRESS: at sentence #1200000, processed 8650606 words, keeping 278457 word types\n",
      "2024-12-17 12:36:02,390 : INFO : PROGRESS: at sentence #1210000, processed 8721893 words, keeping 279959 word types\n",
      "2024-12-17 12:36:02,411 : INFO : PROGRESS: at sentence #1220000, processed 8793795 words, keeping 281427 word types\n",
      "2024-12-17 12:36:02,426 : INFO : PROGRESS: at sentence #1230000, processed 8865726 words, keeping 282981 word types\n",
      "2024-12-17 12:36:02,439 : INFO : PROGRESS: at sentence #1240000, processed 8938173 words, keeping 284542 word types\n",
      "2024-12-17 12:36:02,452 : INFO : PROGRESS: at sentence #1250000, processed 9010842 words, keeping 286064 word types\n",
      "2024-12-17 12:36:02,465 : INFO : PROGRESS: at sentence #1260000, processed 9083261 words, keeping 287521 word types\n",
      "2024-12-17 12:36:02,479 : INFO : PROGRESS: at sentence #1270000, processed 9155616 words, keeping 288987 word types\n",
      "2024-12-17 12:36:02,492 : INFO : collected 290418 word types from a corpus of 9227204 raw words and 1280000 sentences\n",
      "2024-12-17 12:36:02,493 : INFO : Creating a fresh vocabulary\n",
      "2024-12-17 12:36:02,614 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 30369 unique words (10.46% of original 290418, drops 260049)', 'datetime': '2024-12-17T12:36:02.614414', 'gensim': '4.3.3', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "2024-12-17 12:36:02,615 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 8780739 word corpus (95.16% of original 9227204, drops 446465)', 'datetime': '2024-12-17T12:36:02.615425', 'gensim': '4.3.3', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "2024-12-17 12:36:02,778 : INFO : deleting the raw counts dictionary of 290418 items\n",
      "2024-12-17 12:36:02,782 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-12-17 12:36:02,783 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 8222658.616429881 word corpus (93.6%% of prior 8780739)', 'datetime': '2024-12-17T12:36:02.783607', 'gensim': '4.3.3', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "2024-12-17 12:36:03,041 : INFO : estimated required memory for 30369 words and 300 dimensions: 88070100 bytes\n",
      "2024-12-17 12:36:03,042 : INFO : resetting layer weights\n",
      "2024-12-17 12:36:03,077 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-12-17T12:36:03.077783', 'gensim': '4.3.3', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'build_vocab'}\n"
     ]
    }
   ],
   "source": [
    "#Budowanie słowanika \n",
    "w2v_model.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "254d3a21-9296-4449-a57c-e2f0048bc935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 30369\n"
     ]
    }
   ],
   "source": [
    "words = list(w2v_model.wv.index_to_key)  # List of vocabulary words\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3e6eb61-69c5-4dc1-be0b-3062f9776f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 12:36:03,087 : INFO : Word2Vec lifecycle event {'msg': 'training model with 8 workers on 30369 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2024-12-17T12:36:03.087956', 'gensim': '4.3.3', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'train'}\n",
      "2024-12-17 12:36:04,106 : INFO : EPOCH 0 - PROGRESS: at 27.64% examples, 2267289 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:05,106 : INFO : EPOCH 0 - PROGRESS: at 56.18% examples, 2308736 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:06,107 : INFO : EPOCH 0 - PROGRESS: at 85.23% examples, 2333879 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:36:06,604 : INFO : EPOCH 0: training on 9227204 raw words (8222483 effective words) took 3.5s, 2349101 effective words/s\n",
      "2024-12-17 12:36:07,619 : INFO : EPOCH 1 - PROGRESS: at 27.64% examples, 2266903 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:08,621 : INFO : EPOCH 1 - PROGRESS: at 55.97% examples, 2298194 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:09,628 : INFO : EPOCH 1 - PROGRESS: at 82.64% examples, 2257671 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:10,206 : INFO : EPOCH 1: training on 9227204 raw words (8222325 effective words) took 3.6s, 2290754 effective words/s\n",
      "2024-12-17 12:36:11,219 : INFO : EPOCH 2 - PROGRESS: at 27.42% examples, 2251729 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:12,219 : INFO : EPOCH 2 - PROGRESS: at 56.18% examples, 2310166 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:13,221 : INFO : EPOCH 2 - PROGRESS: at 84.37% examples, 2311534 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:13,734 : INFO : EPOCH 2: training on 9227204 raw words (8222441 effective words) took 3.5s, 2338661 effective words/s\n",
      "2024-12-17 12:36:14,770 : INFO : EPOCH 3 - PROGRESS: at 28.40% examples, 2315003 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:15,770 : INFO : EPOCH 3 - PROGRESS: at 57.60% examples, 2358505 words/s, in_qsize 14, out_qsize 0\n",
      "2024-12-17 12:36:16,772 : INFO : EPOCH 3 - PROGRESS: at 87.18% examples, 2382188 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:17,221 : INFO : EPOCH 3: training on 9227204 raw words (8222070 effective words) took 3.5s, 2376775 effective words/s\n",
      "2024-12-17 12:36:18,236 : INFO : EPOCH 4 - PROGRESS: at 28.72% examples, 2358151 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:36:19,240 : INFO : EPOCH 4 - PROGRESS: at 59.01% examples, 2422612 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:36:20,242 : INFO : EPOCH 4 - PROGRESS: at 88.59% examples, 2422882 words/s, in_qsize 16, out_qsize 1\n",
      "2024-12-17 12:36:20,613 : INFO : EPOCH 4: training on 9227204 raw words (8221994 effective words) took 3.4s, 2434319 effective words/s\n",
      "2024-12-17 12:36:21,637 : INFO : EPOCH 5 - PROGRESS: at 28.72% examples, 2345705 words/s, in_qsize 14, out_qsize 1\n",
      "2024-12-17 12:36:22,638 : INFO : EPOCH 5 - PROGRESS: at 57.71% examples, 2364998 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:23,640 : INFO : EPOCH 5 - PROGRESS: at 85.13% examples, 2326517 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:24,136 : INFO : EPOCH 5: training on 9227204 raw words (8223883 effective words) took 3.5s, 2345452 effective words/s\n",
      "2024-12-17 12:36:25,149 : INFO : EPOCH 6 - PROGRESS: at 27.75% examples, 2278185 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:26,153 : INFO : EPOCH 6 - PROGRESS: at 56.29% examples, 2310707 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:27,156 : INFO : EPOCH 6 - PROGRESS: at 84.69% examples, 2316095 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:27,673 : INFO : EPOCH 6: training on 9227204 raw words (8221874 effective words) took 3.5s, 2332823 effective words/s\n",
      "2024-12-17 12:36:28,690 : INFO : EPOCH 7 - PROGRESS: at 29.59% examples, 2416239 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:29,692 : INFO : EPOCH 7 - PROGRESS: at 59.87% examples, 2452962 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:30,695 : INFO : EPOCH 7 - PROGRESS: at 89.56% examples, 2446291 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:36:31,024 : INFO : EPOCH 7: training on 9227204 raw words (8222903 effective words) took 3.3s, 2461309 effective words/s\n",
      "2024-12-17 12:36:32,042 : INFO : EPOCH 8 - PROGRESS: at 27.20% examples, 2230422 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:33,045 : INFO : EPOCH 8 - PROGRESS: at 56.08% examples, 2302447 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:34,045 : INFO : EPOCH 8 - PROGRESS: at 84.80% examples, 2320622 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:34,562 : INFO : EPOCH 8: training on 9227204 raw words (8222508 effective words) took 3.5s, 2334664 effective words/s\n",
      "2024-12-17 12:36:35,578 : INFO : EPOCH 9 - PROGRESS: at 27.96% examples, 2295273 words/s, in_qsize 15, out_qsize 1\n",
      "2024-12-17 12:36:36,580 : INFO : EPOCH 9 - PROGRESS: at 57.06% examples, 2343851 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:37,585 : INFO : EPOCH 9 - PROGRESS: at 86.10% examples, 2353800 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:38,065 : INFO : EPOCH 9: training on 9227204 raw words (8223232 effective words) took 3.5s, 2357177 effective words/s\n",
      "2024-12-17 12:36:39,081 : INFO : EPOCH 10 - PROGRESS: at 29.70% examples, 2434181 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:40,089 : INFO : EPOCH 10 - PROGRESS: at 59.55% examples, 2437891 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:41,092 : INFO : EPOCH 10 - PROGRESS: at 89.23% examples, 2435212 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:36:41,455 : INFO : EPOCH 10: training on 9227204 raw words (8222310 effective words) took 3.4s, 2435224 effective words/s\n",
      "2024-12-17 12:36:42,475 : INFO : EPOCH 11 - PROGRESS: at 28.29% examples, 2316286 words/s, in_qsize 14, out_qsize 3\n",
      "2024-12-17 12:36:43,477 : INFO : EPOCH 11 - PROGRESS: at 57.27% examples, 2348447 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:44,478 : INFO : EPOCH 11 - PROGRESS: at 86.42% examples, 2363591 words/s, in_qsize 15, out_qsize 1\n",
      "2024-12-17 12:36:44,944 : INFO : EPOCH 11: training on 9227204 raw words (8222306 effective words) took 3.5s, 2367344 effective words/s\n",
      "2024-12-17 12:36:45,958 : INFO : EPOCH 12 - PROGRESS: at 28.72% examples, 2359922 words/s, in_qsize 16, out_qsize 1\n",
      "2024-12-17 12:36:46,959 : INFO : EPOCH 12 - PROGRESS: at 59.01% examples, 2427041 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:47,963 : INFO : EPOCH 12 - PROGRESS: at 88.48% examples, 2422569 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:48,337 : INFO : EPOCH 12: training on 9227204 raw words (8223513 effective words) took 3.4s, 2434078 effective words/s\n",
      "2024-12-17 12:36:49,369 : INFO : EPOCH 13 - PROGRESS: at 28.94% examples, 2375238 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:50,370 : INFO : EPOCH 13 - PROGRESS: at 57.16% examples, 2350113 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:36:51,384 : INFO : EPOCH 13 - PROGRESS: at 86.31% examples, 2354245 words/s, in_qsize 16, out_qsize 2\n",
      "2024-12-17 12:36:51,820 : INFO : EPOCH 13: training on 9227204 raw words (8223208 effective words) took 3.5s, 2381976 effective words/s\n",
      "2024-12-17 12:36:52,834 : INFO : EPOCH 14 - PROGRESS: at 30.02% examples, 2465683 words/s, in_qsize 14, out_qsize 1\n",
      "2024-12-17 12:36:53,837 : INFO : EPOCH 14 - PROGRESS: at 60.96% examples, 2502500 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:54,842 : INFO : EPOCH 14 - PROGRESS: at 92.17% examples, 2519147 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:36:55,086 : INFO : EPOCH 14: training on 9227204 raw words (8222136 effective words) took 3.3s, 2527984 effective words/s\n",
      "2024-12-17 12:36:56,106 : INFO : EPOCH 15 - PROGRESS: at 28.83% examples, 2356404 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:36:57,112 : INFO : EPOCH 15 - PROGRESS: at 58.36% examples, 2386415 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:58,116 : INFO : EPOCH 15 - PROGRESS: at 87.62% examples, 2389611 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:36:58,530 : INFO : EPOCH 15: training on 9227204 raw words (8223175 effective words) took 3.4s, 2397081 effective words/s\n",
      "2024-12-17 12:36:59,542 : INFO : EPOCH 16 - PROGRESS: at 29.05% examples, 2380720 words/s, in_qsize 14, out_qsize 1\n",
      "2024-12-17 12:37:00,548 : INFO : EPOCH 16 - PROGRESS: at 58.47% examples, 2395628 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:37:01,558 : INFO : EPOCH 16 - PROGRESS: at 88.91% examples, 2423378 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:01,916 : INFO : EPOCH 16: training on 9227204 raw words (8221576 effective words) took 3.4s, 2434561 effective words/s\n",
      "2024-12-17 12:37:02,942 : INFO : EPOCH 17 - PROGRESS: at 27.86% examples, 2287660 words/s, in_qsize 16, out_qsize 1\n",
      "2024-12-17 12:37:03,945 : INFO : EPOCH 17 - PROGRESS: at 57.27% examples, 2352451 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:37:04,945 : INFO : EPOCH 17 - PROGRESS: at 86.10% examples, 2357805 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:05,401 : INFO : EPOCH 17: training on 9227204 raw words (8222715 effective words) took 3.5s, 2376933 effective words/s\n",
      "2024-12-17 12:37:06,421 : INFO : EPOCH 18 - PROGRESS: at 29.05% examples, 2376203 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:07,424 : INFO : EPOCH 18 - PROGRESS: at 58.79% examples, 2409608 words/s, in_qsize 13, out_qsize 2\n",
      "2024-12-17 12:37:08,430 : INFO : EPOCH 18 - PROGRESS: at 88.91% examples, 2427596 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:37:08,792 : INFO : EPOCH 18: training on 9227204 raw words (8222623 effective words) took 3.4s, 2435938 effective words/s\n",
      "2024-12-17 12:37:09,807 : INFO : EPOCH 19 - PROGRESS: at 28.94% examples, 2377154 words/s, in_qsize 14, out_qsize 1\n",
      "2024-12-17 12:37:10,809 : INFO : EPOCH 19 - PROGRESS: at 58.14% examples, 2387655 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:37:11,811 : INFO : EPOCH 19 - PROGRESS: at 88.16% examples, 2412599 words/s, in_qsize 15, out_qsize 1\n",
      "2024-12-17 12:37:12,195 : INFO : EPOCH 19: training on 9227204 raw words (8222229 effective words) took 3.4s, 2426348 effective words/s\n",
      "2024-12-17 12:37:13,212 : INFO : EPOCH 20 - PROGRESS: at 28.61% examples, 2335635 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:14,217 : INFO : EPOCH 20 - PROGRESS: at 57.71% examples, 2360792 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:15,220 : INFO : EPOCH 20 - PROGRESS: at 87.18% examples, 2378359 words/s, in_qsize 14, out_qsize 1\n",
      "2024-12-17 12:37:15,636 : INFO : EPOCH 20: training on 9227204 raw words (8223091 effective words) took 3.4s, 2396658 effective words/s\n",
      "2024-12-17 12:37:16,652 : INFO : EPOCH 21 - PROGRESS: at 28.94% examples, 2371469 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:17,660 : INFO : EPOCH 21 - PROGRESS: at 58.79% examples, 2406020 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:18,666 : INFO : EPOCH 21 - PROGRESS: at 88.70% examples, 2418507 words/s, in_qsize 14, out_qsize 1\n",
      "2024-12-17 12:37:19,034 : INFO : EPOCH 21: training on 9227204 raw words (8222653 effective words) took 3.4s, 2429206 effective words/s\n",
      "2024-12-17 12:37:20,053 : INFO : EPOCH 22 - PROGRESS: at 29.37% examples, 2403215 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:37:21,056 : INFO : EPOCH 22 - PROGRESS: at 59.87% examples, 2455178 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:22,058 : INFO : EPOCH 22 - PROGRESS: at 89.13% examples, 2436698 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:37:22,417 : INFO : EPOCH 22: training on 9227204 raw words (8221961 effective words) took 3.4s, 2440722 effective words/s\n",
      "2024-12-17 12:37:23,439 : INFO : EPOCH 23 - PROGRESS: at 28.72% examples, 2339630 words/s, in_qsize 16, out_qsize 3\n",
      "2024-12-17 12:37:24,443 : INFO : EPOCH 23 - PROGRESS: at 57.81% examples, 2363401 words/s, in_qsize 16, out_qsize 1\n",
      "2024-12-17 12:37:25,445 : INFO : EPOCH 23 - PROGRESS: at 87.29% examples, 2381824 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:25,875 : INFO : EPOCH 23: training on 9227204 raw words (8222690 effective words) took 3.4s, 2387751 effective words/s\n",
      "2024-12-17 12:37:26,891 : INFO : EPOCH 24 - PROGRESS: at 28.50% examples, 2339992 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:27,892 : INFO : EPOCH 24 - PROGRESS: at 58.14% examples, 2388925 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:37:28,894 : INFO : EPOCH 24 - PROGRESS: at 87.94% examples, 2407542 words/s, in_qsize 16, out_qsize 1\n",
      "2024-12-17 12:37:29,305 : INFO : EPOCH 24: training on 9227204 raw words (8223271 effective words) took 3.4s, 2407591 effective words/s\n",
      "2024-12-17 12:37:30,320 : INFO : EPOCH 25 - PROGRESS: at 28.83% examples, 2366321 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:31,322 : INFO : EPOCH 25 - PROGRESS: at 58.14% examples, 2387582 words/s, in_qsize 15, out_qsize 1\n",
      "2024-12-17 12:37:32,325 : INFO : EPOCH 25 - PROGRESS: at 88.48% examples, 2421149 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:32,692 : INFO : EPOCH 25: training on 9227204 raw words (8223147 effective words) took 3.4s, 2437443 effective words/s\n",
      "2024-12-17 12:37:33,713 : INFO : EPOCH 26 - PROGRESS: at 27.53% examples, 2261109 words/s, in_qsize 14, out_qsize 1\n",
      "2024-12-17 12:37:34,715 : INFO : EPOCH 26 - PROGRESS: at 56.84% examples, 2335104 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:37:35,720 : INFO : EPOCH 26 - PROGRESS: at 85.77% examples, 2345337 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:36,191 : INFO : EPOCH 26: training on 9227204 raw words (8222499 effective words) took 3.5s, 2363452 effective words/s\n",
      "2024-12-17 12:37:37,213 : INFO : EPOCH 27 - PROGRESS: at 28.50% examples, 2329512 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:38,216 : INFO : EPOCH 27 - PROGRESS: at 58.14% examples, 2381367 words/s, in_qsize 14, out_qsize 2\n",
      "2024-12-17 12:37:39,218 : INFO : EPOCH 27 - PROGRESS: at 87.83% examples, 2399338 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:39,615 : INFO : EPOCH 27: training on 9227204 raw words (8222991 effective words) took 3.4s, 2412862 effective words/s\n",
      "2024-12-17 12:37:40,628 : INFO : EPOCH 28 - PROGRESS: at 28.29% examples, 2322782 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:37:41,629 : INFO : EPOCH 28 - PROGRESS: at 56.95% examples, 2341005 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:42,632 : INFO : EPOCH 28 - PROGRESS: at 86.75% examples, 2374407 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:43,060 : INFO : EPOCH 28: training on 9227204 raw words (8222716 effective words) took 3.4s, 2394576 effective words/s\n",
      "2024-12-17 12:37:44,103 : INFO : EPOCH 29 - PROGRESS: at 30.02% examples, 2445514 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:37:45,103 : INFO : EPOCH 29 - PROGRESS: at 60.09% examples, 2460090 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:46,107 : INFO : EPOCH 29 - PROGRESS: at 91.42% examples, 2494730 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:37:46,375 : INFO : EPOCH 29: training on 9227204 raw words (8221956 effective words) took 3.3s, 2506102 effective words/s\n",
      "2024-12-17 12:37:47,391 : INFO : EPOCH 30 - PROGRESS: at 27.64% examples, 2266073 words/s, in_qsize 16, out_qsize 0\n",
      "2024-12-17 12:37:48,393 : INFO : EPOCH 30 - PROGRESS: at 56.51% examples, 2321062 words/s, in_qsize 14, out_qsize 1\n",
      "2024-12-17 12:37:49,403 : INFO : EPOCH 30 - PROGRESS: at 86.31% examples, 2355557 words/s, in_qsize 14, out_qsize 3\n",
      "2024-12-17 12:37:49,843 : INFO : EPOCH 30: training on 9227204 raw words (8222762 effective words) took 3.5s, 2381059 effective words/s\n",
      "2024-12-17 12:37:50,859 : INFO : EPOCH 31 - PROGRESS: at 28.40% examples, 2328191 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:51,859 : INFO : EPOCH 31 - PROGRESS: at 57.49% examples, 2362301 words/s, in_qsize 15, out_qsize 0\n",
      "2024-12-17 12:37:52,864 : INFO : EPOCH 31 - PROGRESS: at 87.07% examples, 2381242 words/s, in_qsize 14, out_qsize 1\n",
      "2024-12-17 12:37:53,293 : INFO : EPOCH 31: training on 9227204 raw words (8222789 effective words) took 3.4s, 2393063 effective words/s\n",
      "2024-12-17 12:37:53,294 : INFO : Word2Vec lifecycle event {'msg': 'training on 295270528 raw words (263124030 effective words) took 110.2s, 2387578 effective words/s', 'datetime': '2024-12-17T12:37:53.294661', 'gensim': '4.3.3', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(263124030, 295270528)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75c4756c-5cce-4a28-9695-9015b2de0741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('luv', 0.5765488147735596), ('loves', 0.5636578798294067), ('loved', 0.5434289574623108), ('adore', 0.50634765625), ('amazing', 0.48880043625831604), ('looove', 0.4886596202850342), ('awesome', 0.4601627588272095), ('loooove', 0.45898008346557617), ('looooove', 0.4411940574645996), ('lovee', 0.43854889273643494)]\n"
     ]
    }
   ],
   "source": [
    "#pokaz efektów - program wyświetlna słowa najbardziej podobne do słowa \"miłość\" (love)\n",
    "similar_words = w2v_model.wv.most_similar(\"love\")\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04be3ecf-ae53-4759-a7cc-52057018da2b",
   "metadata": {},
   "source": [
    "**Tokenizacja Tekstu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa2b2f59-ca3b-4b28-8006-f66837a4f21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words 290419\n",
      "CPU times: total: 12 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train.text)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Total words\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40eeb8dc-7fb7-42f1-b241-b520027533b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 17.5 s\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = pad_sequences(tokenizer.texts_to_sequences(df_train.text), maxlen=SEQUENCE_LENGTH)\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(df_test.text), maxlen=SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40c5486f-cb22-4719-be4e-c240956420dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POSITIVE', 'NEGATIVE', 'NEUTRAL']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df_train.target.unique().tolist()\n",
    "labels.append(NEUTRAL)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a397b80-fb3b-414d-9b60-4262bdef252d",
   "metadata": {},
   "source": [
    "**Podział danych na testowe i treningowe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fdf296e-6842-419b-a764-59923e8d163e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (1280000, 1)\n",
      "y_test (320000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Tworzenie danych treningowych oraz testowych, poprzez otagowanie tekstów. \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_train.target.tolist())\n",
    "\n",
    "y_train = encoder.transform(df_train.target.tolist())\n",
    "y_test = encoder.transform(df_test.target.tolist())\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec55e540-a202-4cda-b1f7-c592176b5743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zapisywanie danych treningowych oraz testowych w osobnych plikach na potrzeby testów\n",
    "\n",
    "output_dir = \"Dane\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "np.savetxt(os.path.join(output_dir, 'y_train.txt'), y_train)\n",
    "np.savetxt(os.path.join(output_dir, 'y_test.txt'), y_test)\n",
    "np.savetxt(os.path.join(output_dir, 'x_train.txt'), x_train)\n",
    "np.savetxt(os.path.join(output_dir, 'x_test.txt'), x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7122af-c385-4f8f-a66b-fb14dbc1b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stan danych uczących się i treningowych\n",
    "#Dane tekstu mają 300 wymiarów (x) zarówno w danych treningowych oraz testowych, tak jak wektory słów\n",
    "#Dane klas mają tylko 1 wymiar (y)\n",
    "\n",
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print()\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fe9fc3-4686-4810-ac6a-e48876e3b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cb7f4e-f26c-4f4a-8208-dfe0e6e62541",
   "metadata": {},
   "source": [
    "Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a28e50f-c075-418c-9f96-cb967eea0b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290419, 300)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "  if word in w2v_model.wv:\n",
    "    embedding_matrix[i] = w2v_model.wv[word]\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c78a26a9-a840-42f9-bd4f-f44654cf8134",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size, W2V_SIZE, weights=[embedding_matrix], trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e5f74fc-0569-4133-b70a-e647b91c947b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">87,125,700</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │      \u001b[38;5;34m87,125,700\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">87,125,700</span> (332.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m87,125,700\u001b[0m (332.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">87,125,700</span> (332.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m87,125,700\u001b[0m (332.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb344df-b7e5-4564-a593-aafa9870f632",
   "metadata": {},
   "source": [
    "Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1449582-5217-473e-b36b-da0e3f293d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a662f4-c5c5-48fe-947b-dbc4e3a86106",
   "metadata": {},
   "source": [
    "Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "79b4460f-c154-470d-a1db-0c3ba1421e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "              EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c3a5cc-76bb-4ace-8fc7-3f6f5c6d0026",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b630ffb-6d3b-45c2-b396-9d6de653ac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2177s\u001b[0m 2s/step - accuracy: 0.7307 - loss: 0.5288 - val_accuracy: 0.7786 - val_loss: 0.4644\n",
      "Epoch 2/8\n",
      "\u001b[1m1048/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1:34\u001b[0m 1s/step - accuracy: 0.7638 - loss: 0.4842 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:6\u001b[0m\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_accuracy', mode='max', patience=3, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebccdab-a9a5-427f-a108-ade734aaddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if history and 'accuracy' in history.history:\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Training did not complete successfully. No history available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0661ea95-5f53-47d9-ab1a-9057f3deaeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(KERAS_MODEL)\n",
    "#w2v_model.save(WORD2VEC_MODEL)\n",
    "#pickle.dump(tokenizer, open(TOKENIZER_MODEL, \"wb\"), protocol=0)\n",
    "#pickle.dump(encoder, open(ENCODER_MODEL, \"wb\"), protocol=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
